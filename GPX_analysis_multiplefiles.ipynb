{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPX data analysis (multiple files)\n",
    "\n",
    "This notebook contains some Python test code to analyze and visualize GPX data from a multiple files. GPX (GPS Exchange Format) is an XML based file format for GPS tracks, and is widely used by dozens of software programs and web services for GPS data analysis and visualization. \n",
    "\n",
    "Data manipulation is done using [gpxpy](https://github.com/tkrajina/gpxpy), a GPX parser for Python, and the [NumPy](http://www.numpy.org/) and [Pandas](https://pandas.pydata.org/) data analysis packages for Python. Visualization is done using [gmplot](https://github.com/vgm64/gmplot) and [folium](https://github.com/python-visualization/folium).\n",
    "\n",
    "## Prerequisites:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: gmalim\n",
      "\n",
      "last updated: Wed Jul 18 2018\n",
      "\n",
      "CPython 3.6.5\n",
      "IPython 6.4.0\n",
      "\n",
      "gpxpy n\u0007\n",
      "numpy 1.14.5\n",
      "pandas 0.23.3\n",
      "gmplot n\u0007\n",
      "folium 0.5.0+145.gb7b31aa\n",
      "\n",
      "compiler   : GCC 4.2.1 Compatible Apple LLVM 8.0.0 (clang-800.0.42.1)\n",
      "system     : Darwin\n",
      "release    : 15.6.0\n",
      "machine    : x86_64\n",
      "processor  : i386\n",
      "CPU cores  : 2\n",
      "interpreter: 64bit\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import glob # module to find all pathnames matching a specified pattern\n",
    "import os\n",
    "\n",
    "import gpxpy\n",
    "import numpy  as np\n",
    "import pandas as pd\n",
    "import gmplot\n",
    "import folium\n",
    "from folium import plugins\n",
    "\n",
    "%load_ext watermark\n",
    "%watermark -a \"Author: gmalim\" \n",
    "print(\"\")\n",
    "%watermark -u -n\n",
    "print(\"\")\n",
    "%watermark -v -p gpxpy,numpy,pandas,gmplot,folium\n",
    "print(\"\")\n",
    "%watermark -m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data:\n",
    "\n",
    "Create function to load list of GPX files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_run_data(gpx_path, filter=\"*\"):\n",
    "    \"\"\"\n",
    "    Loop over files, tracks, segments and points.\n",
    "    \"\"\"\n",
    "    \n",
    "    gpx_files = glob.glob(os.path.join(gpx_path, filter + \".gpx\"))\n",
    "    \n",
    "    gpx_points = []\n",
    "    \n",
    "    total_track_length   = 0\n",
    "    total_track_duration = 0\n",
    "    \n",
    "    trainingrun_id = 1\n",
    "\n",
    "    for file_idx, gpx_file in enumerate(gpx_files):\n",
    "    \n",
    "        print(\"--> Processing file\", file_idx)\n",
    "        \n",
    "        gpx = gpxpy.parse(open(gpx_file, 'r'))\n",
    "        \n",
    "        for track_idx, track in enumerate(gpx.tracks):\n",
    "            \n",
    "            #print(\"---> Processing track\", track_idx)\n",
    "            \n",
    "            track_name     = track.name\n",
    "            track_length   = track.length_3d()\n",
    "            track_duration = track.get_duration()\n",
    "\n",
    "            total_track_length   += track_length\n",
    "            total_track_duration += track_duration\n",
    "                        \n",
    "            if (track_name == 'Training run'):\n",
    "                track_name += ' {}'.format(trainingrun_id) \n",
    "                trainingrun_id += 1\n",
    "               \n",
    "            #track_name += ' ({:.0f} km)'.format(track.length_3d()/1e3)\n",
    "            \n",
    "            for seg_idx, segment in enumerate(track.segments):\n",
    "                \n",
    "                #print(\"----> Processing segment\", seg_idx)\n",
    "                \n",
    "                #segment_length = segment.length_3d()\n",
    "                \n",
    "                for point_idx, point in enumerate(segment.points):\n",
    "                    \n",
    "                    #print(\"----> Processing point\", point_idx)\n",
    "                    \n",
    "                    gpx_points.append([\n",
    "                                       track_name,\n",
    "                                       point.time,\n",
    "                                       point.latitude, \n",
    "                                       point.longitude, \n",
    "                                       #point.elevation, \n",
    "                                       #segment.get_speed(point_idx)\n",
    "                                      ])\n",
    "                    \n",
    "    return gpx_points, total_track_length, total_track_duration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load list of GPX files and parse data to dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Processing file 0\n",
      "--> Processing file 1\n",
      "--> Processing file 2\n",
      "--> Processing file 3\n",
      "--> Processing file 4\n",
      "--> Processing file 5\n",
      "--> Processing file 6\n",
      "\n",
      "Total distance as summed between points in track =  72.33 miles\n",
      "Total distance as summed between points in track = 116.40 km\n",
      "Total time     as summed between points in track =  13.34 hours\n"
     ]
    }
   ],
   "source": [
    "gpx_points, total_track_length, total_track_duration = load_run_data(gpx_path='./data/', filter=\"*\")\n",
    "\n",
    "print('')\n",
    "print('Total distance as summed between points in track = {:6.2f} miles'.format(total_track_length*0.000621371))\n",
    "print('Total distance as summed between points in track = {:6.2f} km'   .format(total_track_length*0.001))\n",
    "print('Total time     as summed between points in track = {:6.2f} hours'.format(total_track_duration/3600))\n",
    "\n",
    "column_list = [\n",
    "               'Track_Name',\n",
    "               'Point_Time', \n",
    "               'Point_Latitude',\n",
    "               'Point_Longitude', \n",
    "               #'Point_Elevation', \n",
    "               #'Point_Speed'\n",
    "              ]\n",
    "\n",
    "df = pd.DataFrame(gpx_points, columns=column_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional: Save dataframe using pickle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46651, 4)\n",
      "             Track_Name          Point_Time  Point_Latitude  Point_Longitude\n",
      "0  Bay to Breakers 2016 2016-05-15 15:07:53       37.790538      -122.393670\n",
      "1  Bay to Breakers 2016 2016-05-15 15:07:54       37.790533      -122.393673\n",
      "2  Bay to Breakers 2016 2016-05-15 15:07:55       37.790526      -122.393684\n",
      "3  Bay to Breakers 2016 2016-05-15 15:07:56       37.790527      -122.393673\n",
      "4  Bay to Breakers 2016 2016-05-15 15:07:57       37.790519      -122.393669\n"
     ]
    }
   ],
   "source": [
    "df.to_pickle(\"alldata.pkl\")\n",
    "\n",
    "print(df.shape)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional: Load dataframe from pickled file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46651, 4)\n",
      "             Track_Name          Point_Time  Point_Latitude  Point_Longitude\n",
      "0  Bay to Breakers 2016 2016-05-15 15:07:53       37.790538      -122.393670\n",
      "1  Bay to Breakers 2016 2016-05-15 15:07:54       37.790533      -122.393673\n",
      "2  Bay to Breakers 2016 2016-05-15 15:07:55       37.790526      -122.393684\n",
      "3  Bay to Breakers 2016 2016-05-15 15:07:56       37.790527      -122.393673\n",
      "4  Bay to Breakers 2016 2016-05-15 15:07:57       37.790519      -122.393669\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_pickle(\"alldata.pkl\")\n",
    "\n",
    "print(df.shape)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional: Select data according to time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46651, 4)\n",
      "             Track_Name          Point_Time  Point_Latitude  Point_Longitude\n",
      "0  Bay to Breakers 2016 2016-05-15 15:07:53       37.790538      -122.393670\n",
      "1  Bay to Breakers 2016 2016-05-15 15:07:54       37.790533      -122.393673\n",
      "2  Bay to Breakers 2016 2016-05-15 15:07:55       37.790526      -122.393684\n",
      "3  Bay to Breakers 2016 2016-05-15 15:07:56       37.790527      -122.393673\n",
      "4  Bay to Breakers 2016 2016-05-15 15:07:57       37.790519      -122.393669\n"
     ]
    }
   ],
   "source": [
    "df['Point_Time'] = pd.to_datetime(df['Point_Time'])\n",
    "\n",
    "start_date = pd.Timestamp(2015,1,1)   \n",
    "end_date   = pd.Timestamp(2018,1,1)   \n",
    "\n",
    "mask = ((df['Point_Time'] > start_date) & (df['Point_Time'] <= end_date))\n",
    "\n",
    "df = df.loc[mask]\n",
    "\n",
    "print(df.shape)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization:\n",
    "\n",
    "Create heatmap using **gmplot**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "map_center_lat =   37.796 degrees\n",
      "map_center_lon = -122.439 degrees\n"
     ]
    }
   ],
   "source": [
    "map_center_lat = df.Point_Latitude .mean() + 0.01\n",
    "map_center_lon = df.Point_Longitude.mean()\n",
    "\n",
    "print(\"map_center_lat = {:8.3f} degrees\".format(map_center_lat))\n",
    "print(\"map_center_lon = {:8.3f} degrees\".format(map_center_lon))\n",
    "\n",
    "gmap = gmplot.GoogleMapPlotter(map_center_lat, map_center_lon, 13) # lat & lon of map center and map zoom level\n",
    "\n",
    "gmap.heatmap(df['Point_Latitude'], df['Point_Longitude'], maxIntensity=100)\n",
    "\n",
    "gmap.draw(\"gmplot_heatmap.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"100%\" height=\"700\" src=\"gmplot_heatmap.html\"></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<iframe width=\"100%\" height=\"700\" src=\"gmplot_heatmap.html\"></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create heatmap using **folium**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List comprehension to make out list of lists needed for folium.plugins.HeatMap class:\n",
    "\n",
    "heat_data = [[row['Point_Latitude'],row['Point_Longitude']] for index, row in df.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Processing Bay to Breakers 2016\n",
      "--> Processing Bay to Breakers 2017\n",
      "--> Processing SF Marathon 2015\n",
      "--> Processing Training run 1\n",
      "--> Processing Training run 2\n",
      "--> Processing Training run 3\n",
      "--> Processing Training run 4\n"
     ]
    }
   ],
   "source": [
    "# Create basemap:\n",
    "\n",
    "fmap = folium.Map(location=[map_center_lat, map_center_lon], zoom_start = 13, control_scale = True, tiles=None)\n",
    "\n",
    "# Add tileset layers to map: \n",
    "\n",
    "# Option 1 - Use built-in tilesets:\n",
    "\n",
    "builtin_tilesets = [#'OpenStreetMap', \n",
    "                    #'Mapbox Bright', \n",
    "                    #'Mapbox Control Room', \n",
    "                    'CartoDB Positron', \n",
    "                    'CartoDB Dark_Matter',\n",
    "                    #'Stamen Toner', \n",
    "                    #'Stamen Watercolor',\n",
    "                    #'Stamen Terrain'\n",
    "                   ]\n",
    "\n",
    "for tileset in builtin_tilesets:\n",
    "    fmap.add_tile_layer(tiles=tileset, name=tileset) #, attr=tileset)\n",
    "\n",
    "# Option 2 - Use tileset servers (See http://leaflet-extras.github.io/leaflet-providers/preview/):\n",
    "\n",
    "#fmap.add_tile_layer(tiles='https://{s}.tile.opentopomap.org/{z}/{x}/{y}.png', name='OpenTopoMap', attr='OpenTopoMap')\n",
    "\n",
    "url_base = 'http://server.arcgisonline.com/ArcGIS/rest/services/'\n",
    "\n",
    "mapservernames = [#'Ocean_Basemap', \n",
    "                  #'USA_Topo_Maps', \n",
    "                  #'NatGeo_World_Map',\n",
    "                  'World_Imagery', \n",
    "                  #'World_Physical_Map', \n",
    "                  #'World_Street_Map', \n",
    "                  #'World_Terrain_Base', \n",
    "                  #'World_Topo_Map'\n",
    "                 ]\n",
    "\n",
    "for msn in mapservernames:\n",
    "    tileset = url_base + msn + '/MapServer/tile/{z}/{y}/{x}'\n",
    "    fmap.add_tile_layer(tiles=tileset, name=msn, attr=msn)\n",
    "\n",
    "# Add fullscreen button:\n",
    "\n",
    "plugins.Fullscreen(\n",
    "    position='topleft',\n",
    "    title='Enter fullscreen-mode',\n",
    "    title_cancel='Exit fullscreen-mode',\n",
    "    force_separate_button=True).add_to(fmap)\n",
    "\n",
    "# Add button to enabling/disabling scrolling - DOESN'T WORK?:\n",
    "\n",
    "# plugins.ScrollZoomToggler().add_to(fmap)\n",
    "\n",
    "# Add latitude-longitude popup click-tool:\n",
    "\n",
    "fmap.add_child(folium.LatLngPopup())\n",
    "\n",
    "# Add HeatMap as FeatureGroup:\n",
    "\n",
    "hm = plugins.HeatMap(heat_data, radius=5, blur=0.25, min_opacity=0.15, max_val=1e2, max_zoom=13)\n",
    "\n",
    "h = folium.FeatureGroup(name='Heat Map')\n",
    "h.add_child(hm)\n",
    "fmap.add_child(h)\n",
    "\n",
    "# Split dataframe by trackname and add each track & minute-spread points along the track as a FeatureGroup:\n",
    "\n",
    "grouped = df.groupby(['Track_Name'])\n",
    "\n",
    "for track_name in df.Track_Name.unique():\n",
    "    \n",
    "    dftmp = grouped.get_group(track_name)\n",
    "\n",
    "    print(\"--> Processing\", track_name)\n",
    "    #print(dftmp.shape)\n",
    "\n",
    "    fg = folium.FeatureGroup(name=track_name, show=False)\n",
    "\n",
    "    polylinepoints = []\n",
    "    for lat, lon in zip(dftmp['Point_Latitude'], dftmp['Point_Longitude']):\n",
    "        polylinepoints.append(tuple([lat,lon]))\n",
    "\n",
    "    pl = folium.PolyLine(locations=polylinepoints, color=\"black\", weight=2, opacity=0.5)\n",
    "    fg.add_child(pl)\n",
    "    \n",
    "    npoints = len(dftmp)\n",
    "    \n",
    "    for i, coord in enumerate(dftmp[['Point_Latitude','Point_Longitude']].values):\n",
    "        \n",
    "        if (i == 0):\n",
    "            m = folium.Marker(location=[coord[0],coord[1]], \n",
    "                              icon=folium.Icon(color='green', prefix='fa', icon='hourglass-start'))\n",
    "            fg.add_child(m)\n",
    "        \n",
    "        if (i == npoints-1):\n",
    "            m = folium.Marker(location=[coord[0],coord[1]], \n",
    "                              icon=folium.Icon(color='red', prefix='fa', icon='hourglass-end'))\n",
    "            fg.add_child(m)\n",
    "        \n",
    "        if (i%60 != 0):\n",
    "            continue\n",
    "            \n",
    "        cm = folium.CircleMarker(location=[coord[0],coord[1]], radius=1, color='magenta')\n",
    "        fg.add_child(cm)\n",
    "                \n",
    "    fmap.add_child(fg)\n",
    "\n",
    "# Add layer-control button:\n",
    "    \n",
    "lc = folium.LayerControl()\n",
    "fmap.add_child(lc)\n",
    "    \n",
    "# Save map:\n",
    "    \n",
    "fmap.save('folium_heatmap.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"100%\" height=\"700\" src=\"folium_heatmap.html\"></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<iframe width=\"100%\" height=\"700\" src=\"folium_heatmap.html\"></iframe>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
